{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load imports\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 120000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# load dataset (task 1)\n",
    "\n",
    "dataset = load_dataset('ag_news')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 96000\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 24000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# split dataset (task 2)\n",
    "\n",
    "split = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "dataset = DatasetDict({\n",
    "    \"train\": split[\"train\"],\n",
    "    \"dev\": split[\"test\"],\n",
    "    \"test\": dataset[\"test\"]\n",
    "})\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Zbiór  Rozmiar  Średnia długość tekstu  Minimalna długość tekstu  \\\n",
      "0  Train    96000               37.842917                         8   \n",
      "1    Dev    24000               37.865583                         8   \n",
      "2   Test     7600               37.722368                        11   \n",
      "\n",
      "   Maksymalna długość tekstu  Odchylenie standardowe  Mediana długości  \\\n",
      "0                        177               10.086832              37.0   \n",
      "1                        157               10.078666              37.0   \n",
      "2                        137               10.129193              37.0   \n",
      "\n",
      "                               Rozkład klas  \n",
      "0  {2: 24061, 1: 23949, 3: 24041, 0: 23949}  \n",
      "1      {0: 6051, 1: 6051, 3: 5959, 2: 5939}  \n",
      "2      {2: 1900, 3: 1900, 1: 1900, 0: 1900}  \n"
     ]
    }
   ],
   "source": [
    "# dataset statistics (task 3)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def dataset_statistics(dataset, name):\n",
    "    text_lengths = [len(text.split()) for text in dataset[\"text\"]]\n",
    "    min_length = np.min(text_lengths)\n",
    "    max_length = np.max(text_lengths)\n",
    "    mean_length = np.mean(text_lengths)\n",
    "    std_length = np.std(text_lengths)\n",
    "    median_length = np.median(text_lengths)\n",
    "    data_size = len(dataset)\n",
    "    class_counts = Counter(dataset[\"label\"])\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"Zbiór\": name,\n",
    "        \"Rozmiar\": data_size,\n",
    "        \"Średnia długość tekstu\": mean_length,\n",
    "        \"Minimalna długość tekstu\": min_length,\n",
    "        \"Maksymalna długość tekstu\": max_length,\n",
    "        \"Odchylenie standardowe\": std_length,\n",
    "        \"Mediana długości\": median_length,\n",
    "        \"Rozkład klas\": dict(class_counts)\n",
    "    }\n",
    "\n",
    "stats_train = dataset_statistics(dataset[\"train\"], \"Train\")\n",
    "stats_dev = dataset_statistics(dataset[\"dev\"], \"Dev\")\n",
    "stats_test = dataset_statistics(dataset[\"test\"], \"Test\")\n",
    "\n",
    "stats = pd.DataFrame([stats_train, stats_dev, stats_test])\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0  Nation #39;s Cotton Crop May Exceed Records Th...      2   \n",
      "1  18 years and still rollin #39; ALEX FERGUSON w...      1   \n",
      "2  Madrid Masters: Safin beats Nalbandian Sunday ...      1   \n",
      "3  Sirius Satellite Signs Howard Stern to 5-Year ...      2   \n",
      "4  NATO, Russia To Meet Over Beslan School Siege ...      3   \n",
      "\n",
      "          label_one_hot  \n",
      "0  [0.0, 0.0, 1.0, 0.0]  \n",
      "1  [0.0, 1.0, 0.0, 0.0]  \n",
      "2  [0.0, 1.0, 0.0, 0.0]  \n",
      "3  [0.0, 0.0, 1.0, 0.0]  \n",
      "4  [0.0, 0.0, 0.0, 1.0]  \n"
     ]
    }
   ],
   "source": [
    "# normalization (task 4)\n",
    "\n",
    "if \"label_one_hot\" in dataset[\"train\"].column_names:\n",
    "    dataset[\"train\"] = dataset[\"train\"].remove_columns(\"label_one_hot\")\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "labels = np.array(dataset[\"train\"][\"label\"]).reshape(-1, 1)\n",
    "one_hot_labels = encoder.fit_transform(labels)\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].add_column(\"label_one_hot\", one_hot_labels.tolist())\n",
    "\n",
    "df = pd.DataFrame(dataset[\"train\"][:5])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 96000/96000 [00:00<00:00, 245746.80 examples/s]\n",
      "Filter: 100%|██████████| 24000/24000 [00:00<00:00, 397910.10 examples/s]\n",
      "Filter: 100%|██████████| 7600/7600 [00:00<00:00, 418598.71 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'label_one_hot'],\n",
      "        num_rows: 96000\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 24000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7600\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# clean dataset (task 5)\n",
    "\n",
    "def validate_samples(sample):\n",
    "    if not sample[\"text\"]:\n",
    "        return False\n",
    "    if sample[\"label\"] not in {0, 1, 2, 3}:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].filter(validate_samples)\n",
    "dataset[\"dev\"] = dataset[\"dev\"].filter(validate_samples)\n",
    "dataset[\"test\"] = dataset[\"test\"].filter(validate_samples)\n",
    "\n",
    "print(dataset)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
